{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5ee9b5",
   "metadata": {},
   "source": [
    "# Vergleich von Imputation Methoden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6372f0a",
   "metadata": {},
   "source": [
    "An dieser Stelle sollen verschiede Methoden zum interpolieren von fehlenden Werten betrachtet und verglichen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e93d63",
   "metadata": {},
   "source": [
    "### Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6a4c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9cbf47",
   "metadata": {},
   "source": [
    "In der Folge werden keine Regionen oder Gruppierungen von Ländern und nur die Jahre ab 1990 betrachtet. \n",
    "Von dem verbliebenen Datensatz werden nur jene Indikatoren behalten, die mindesten 20% gefüllt sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53a06671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_base():\n",
    "    pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "    base= pd.read_csv('../Data/WDIData.csv') #see downloads worldbank\n",
    "    base = base.drop(['Country Code', 'Indicator Code', 'Unnamed: 66'], axis=1) #name of column 'Unnamed: 66' may differ\n",
    "\n",
    "    countries = pd.read_csv('additional_data/countries.csv').drop('Unnamed: 0', axis=1)\n",
    "    base = pd.merge(base, countries, how='left')\n",
    "    base = base.loc[base['Type'] != 'Region'].drop('Type', axis=1)\n",
    "\n",
    "    base = base.set_index(['Country Name', 'Indicator Name'])\n",
    "    base = base.loc[:, '1990':'2020']\n",
    "\n",
    "    idx = pd.IndexSlice\n",
    "    keep = pd.DataFrame(pd.DataFrame(base.isna().groupby('Indicator Name').sum()).T.sum(), columns=['NaN'])\n",
    "    keep = keep.loc[keep['NaN'] <len(base.index.get_level_values('Country Name').unique())*len(base.columns)*0.8] #kept if 80% of entries are not NaN\n",
    "    base = base.loc[idx[:, keep.index], :]\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4810a09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2758915"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = reset_base()\n",
    "base.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684223dd",
   "metadata": {},
   "source": [
    "Um die Performanz unterschiedlicher Imutation Verfahren zu vergleichen werden weitere 1000 vorhandene (nicht NaN) Einträge entfernt. Diese 1000 Einträge werden später als Test-Daten verwendet, auf ihrer Grundlage lassen sich die Fehler der analysierten Verfahren errechnen. Um sicherzustellen, dass die Ergebnisse reproduzierbar sind wird ein Random State gesetzt. Dann werden zufällig Koordinaten zu Dateneinträgen gezogen. Da an dieser Stelle nur vorhandene Einträge relevant sind, werde zunächst zu viele Koordinaten gezogen, diese dann mit dem Datensatz abgeglichen und gelöscht, falls sie zu einem NaN zeigen und dann die ersten 1000 verbliebenen (und damit relevanten) Einträge ausgewählt. Diese werden in den Trainingsdaten entfernt. Auf diese Weise bleibt eine Reproduzierbarkeit erhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af3855",
   "metadata": {},
   "source": [
    "### Simulation fehlender Werte und Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ab75db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random state to ensure reproducibility\n",
    "rnds = np.random.RandomState(999)\n",
    "\n",
    "#coordinates for data entries to be removed randomly\n",
    "#5000 entries are selected\n",
    "cords = pd.DataFrame([[rnds.randint(0, len(base), size=5000)[i], \n",
    "              rnds.randint(0, len(base.columns), size=5000)[i]]\n",
    "              for i in range(5000)])\n",
    "\n",
    "#all coordinates pointing to NaN entries are removed and\n",
    "#first 1000 remaining entries are selected\n",
    "cords['value'] = [base.iloc[cords[0][i], cords[1][i]] for i in cords.index]\n",
    "cords = cords.dropna()[:1000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e83f2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train data by changing randomly chosen values to NaN\n",
    "def reset_train():\n",
    "    train = base.copy()\n",
    "    for i in cords.index:\n",
    "        train.iloc[cords[0][i], cords[1][i]] = None\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a4ee24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df):\n",
    "    #scaling original data and imputed data\n",
    "    #necessary ?????????????????????????????????????\n",
    "    res1 = (pd.DataFrame({'y_true': [base.iloc[cords[0][i], cords[1][i]] for i in cords.index],\n",
    "                        'y_pred': [df.iloc[cords[0][i], cords[1][i]] for i in cords.index],\n",
    "                        'indicator': [df.index.get_level_values('Indicator Name')[cords[0][i]] for i in cords.index],\n",
    "                        'year': [df.columns[cords[1][i]] for i in cords.index]})\n",
    "         )\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler().fit(train) #fitting on train?\n",
    "    norm_base = pd.DataFrame(scaler.transform(base))\n",
    "    df = pd.DataFrame(scaler.transform(df))\n",
    "\n",
    "    #getting imputed values for simulated NaNs and true value \n",
    "    res =pd.DataFrame({'y_true': [norm_base.iloc[cords[0][i], cords[1][i]] for i in cords.index],\n",
    "                       'y_pred': [df.iloc[cords[0][i], cords[1][i]] for i in cords.index]\n",
    "                      })\n",
    "    res = res.dropna()\n",
    "\n",
    "   \n",
    "    #calculate evaluation metrics\n",
    "    r2 = r2_score(res['y_true'], res['y_pred'])\n",
    "    rmse = math.sqrt(mean_squared_error(res['y_true'], res['y_pred']))\n",
    "    still_missing = df.isna().sum().sum()\n",
    "    \n",
    "    print(f'Mit dieser Methode bleiben {still_missing} NaNs bestehen.')\n",
    "    print('')\n",
    "    print(f'{len(res)} Werte wurden für die Metriken verwendet.')\n",
    "    print(f'r2: {r2}, rmse: {rmse}')\n",
    "\n",
    "    return still_missing, r2, rmse\n",
    "    #return res1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e52da5",
   "metadata": {},
   "source": [
    "###  Imputation Verfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48780b94",
   "metadata": {},
   "source": [
    "Es werden diese Imputation Methoden verglichen:\n",
    "- Backcasting\n",
    "- Durchschnitt\n",
    "- regionaler Durchschnitt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1aa949",
   "metadata": {},
   "source": [
    "#### Backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9feab176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_backfill(df):\n",
    "    df = df.fillna(method='bfill', limit=3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15106e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = reset_base()\n",
    "train = reset_train()\n",
    "df3= impute_backfill(train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc23fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit dieser Methode bleiben 962168 NaNs bestehen.\n",
      "\n",
      "956 Werte wurden für die Metriken verwendet.\n",
      "r2: -0.017399825459009977, rmse: 0.3421192666313887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(962168, -0.017399825459009977, 0.3421192666313887)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199e7eb",
   "metadata": {},
   "source": [
    "#### Durchschnitt des Indikators über alle Jahre hinweg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05b74379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_overall_means(df):\n",
    "    #fill NaNs with overall mean of that indicator\n",
    "    values = pd.DataFrame(df.stack()).groupby('Indicator Name')[0].mean()\n",
    "    df = pd.DataFrame(df.stack(dropna=False))\n",
    "    \n",
    "    df[0] = df[0].fillna(df.groupby('Indicator Name')[0].transform('mean'))\n",
    "    df = df.unstack()\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "    df = df5.sort_index(level='Indicator Name')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa5d2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = reset_base()\n",
    "train = reset_train()\n",
    "df1 = impute_overall_means(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "253529b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit dieser Methode bleiben 0 NaNs bestehen.\n",
      "\n",
      "1000 Werte wurden für die Metriken verwendet.\n",
      "r2: -0.27079907766456746, rmse: 0.3738648822249713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, -0.27079907766456746, 0.3738648822249713)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556408e1",
   "metadata": {},
   "source": [
    "#### Durchschnitt des Indikators für das jeweilige Jahr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f848c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_yearly_means(df):\n",
    "    #fill NaNs with overall mean of that indicator\n",
    "    \n",
    "    for i in df.columns:\n",
    "        df[i] = df[i].fillna(df.groupby('Indicator Name')[i].transform('mean'))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "916f6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = reset_base()\n",
    "train = reset_train()\n",
    "df2 = impute_yearly_means(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f202233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit dieser Methode bleiben 549010 NaNs bestehen.\n",
      "\n",
      "1000 Werte wurden für die Metriken verwendet.\n",
      "r2: -0.1390895839539641, rmse: 0.4250060604245091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(549010, -0.1390895839539641, 0.4250060604245091)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36834c68",
   "metadata": {},
   "source": [
    "#### Regionaler Durchschnitt des Indikators für das jeweilige Jahr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b7c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e199a151",
   "metadata": {},
   "source": [
    "#### MICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
